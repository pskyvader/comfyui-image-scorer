{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fac6f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root set to: d:\\Programming\\Python\\comfyui-image-scorer\\full_data\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "from IPython.display import clear_output\n",
    "import warnings\n",
    "# Filter user warnings from sklearn/lgbm to keep output clean\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "p = Path.cwd()\n",
    "# Robust root detection: prefer the ancestor that contains full_data/training\n",
    "root = None\n",
    "for candidate in [p] + list(p.parents):\n",
    "    if (candidate / \"full_data\" / \"training\").exists():\n",
    "        root = candidate\n",
    "        break\n",
    "# Fallback: previous heuristics + scan descendants (handles papermill using parent cwd)\n",
    "if root is None:\n",
    "    root = p\n",
    "    while root.parent != root and not (root / \"pyproject.toml\").exists():\n",
    "        root = root.parent\n",
    "    # If not found upwards, search downwards a few levels for pyproject\n",
    "    if not (root / \"pyproject.toml\").exists():\n",
    "        candidates = list(p.rglob('pyproject.toml'))\n",
    "        print('pyproject candidates (rglob):', candidates)\n",
    "        if candidates:\n",
    "            root = candidates[0].parent\n",
    "    # If not found upwards, search downwards a few levels for pyproject (duplicate check)\n",
    "    if not (root / \"pyproject.toml\").exists():\n",
    "        candidates = list(p.rglob('pyproject.toml'))\n",
    "        if candidates:\n",
    "            root = candidates[0].parent\n",
    "# Ensure the project root and the `full_data` folder are on sys.path\n",
    "sys.path.insert(0, str(root))\n",
    "full_data_path = root / \"full_data\"\n",
    "if full_data_path.exists():\n",
    "    sys.path.insert(0, str(full_data_path))\n",
    "import os\n",
    "print(\"Project root set to:\", root)\n",
    "print(\"Added to sys.path:\", sys.path[0])\n",
    "print('cwd at runtime:', os.getcwd())\n",
    "# Print any papermill-related environment values to help identify the notebook path\n",
    "for k, v in os.environ.items():\n",
    "    if k.startswith('PAPERMILL') or 'NOTEBOOK' in k.upper() or k in ('PWD', 'PYTHONPATH'):\n",
    "        print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac8a083",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mimportlib\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtraining\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata_utils\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtraining\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrun\u001b[39;00m\n\u001b[32m      4\u001b[39m importlib.reload(training.data_utils)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Programming\\Python\\comfyui-image-scorer\\full_data\\training\\data_utils.py:5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PolynomialFeatures\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m r2_score\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgc\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtqdm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tqdm\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "print('Diagnostics — cwd:', os.getcwd())\n",
    "print('Diagnostics — sys.path[0:3]:', sys.path[:3])\n",
    "import importlib\n",
    "try:\n",
    "    import training.data_utils\n",
    "    import training.run\n",
    "    importlib.reload(training.data_utils)\n",
    "    importlib.reload(training.run)\n",
    "    from training.run import train_model, optimize_hyperparameters\n",
    "    print(\"Modules reloaded.\")\n",
    "except Exception as e:\n",
    "    print('Import error while loading training modules:', type(e), e)\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903666ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Live plot will be saved to: c:\\ComfyUI\\trainer\\training\\output\\graph_hpo.png\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Reload shared.config to ensure detailed clean state (fix for AutoSaveDict recursion bug)\n",
    "import shared.config\n",
    "\n",
    "importlib.reload(shared.config)\n",
    "from shared.config import config\n",
    "\n",
    "# Reload training.run to use the new config object\n",
    "import training.run\n",
    "# Reload data_utils to pick up new interaction logic\n",
    "import training.data_utils \n",
    "import training.config_utils\n",
    "\n",
    "importlib.reload(training.run)\n",
    "importlib.reload(training.data_utils)\n",
    "importlib.reload(training.config_utils)\n",
    "\n",
    "from training.run import (\n",
    "    LivePlotCallback,\n",
    "    prepare_optimization_setup,\n",
    "    generate_combos,\n",
    "    evaluate_hyperparameter_combo,\n",
    "    optimize_hyperparameters\n",
    ")\n",
    "from training.helpers import resolve_path\n",
    "# Import granular steps for explicit pipeline\n",
    "from training.data_utils import (\n",
    "    load_training_data, \n",
    "    filter_unused_features, \n",
    "    add_interaction_features\n",
    ")\n",
    "\n",
    "# Set output path for live graph\n",
    "config[\"training\"][\"live_graph_path\"] = \"training/output/graph_hpo.png\"\n",
    "live_plot_path = resolve_path(config[\"training\"][\"live_graph_path\"])\n",
    "print(f\"Live plot will be saved to: {live_plot_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0424fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step 1: Loading Data ---\n",
      "Loaded Data Shape: (6495, 2322)\n",
      "\n",
      "--- Step 2: Filtering Unused Features ---\n",
      "Filtering features... Initial shape: (6495, 2322)\n",
      "Loading filtered data from cache: C:\\ComfyUI\\trainer\\training\\output\\filtered_data_cache.npz\n",
      "Filtered Data Shape: (6495, 1357)\n",
      "\n",
      "--- Step 3: Generating Interaction Features ---\n",
      "Loading interaction data from cache: C:\\ComfyUI\\trainer\\training\\output\\interaction_data_cache.npz\n",
      "Final Data Shape (with Interactions): (6495, 1857)\n",
      "Data Preparation Complete.\n"
     ]
    }
   ],
   "source": [
    "# Pre-load and Process Data Explicitly\n",
    "vectors_path = resolve_path(config[\"vectors_file\"])\n",
    "scores_path = resolve_path(config[\"scores_file\"])\n",
    "\n",
    "print(\"--- Step 1: Loading Data ---\")\n",
    "X, y = load_training_data(vectors_path, scores_path)\n",
    "print(f\"Loaded Data Shape: {X.shape}\")\n",
    "\n",
    "print(\"\\n--- Step 2: Filtering Unused Features ---\")\n",
    "# Removes features with zero variance or zero importance in a quick probe\n",
    "X, kept_indices = filter_unused_features(X, y)\n",
    "print(f\"Filtered Data Shape: {X.shape}\")\n",
    "\n",
    "print(\"\\n--- Step 3: Generating Interaction Features ---\")\n",
    "# Adds top 500 polynomial interactions (feature_A * feature_B)\n",
    "X, _ = add_interaction_features(X, y, target_k=200)\n",
    "print(f\"Final Data Shape (with Interactions): {X.shape}\")\n",
    "print(\"Data Preparation Complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385ad283",
   "metadata": {},
   "source": [
    "### Optimization Pipeline Confirmation\n",
    "\n",
    "You asked: *\"Are you doing all 3 optimizations before starting with the hyperparameters?\"*\n",
    "\n",
    "**Answer:**\n",
    "1.  **Filtering**: Yes, applied in Step 2 above.\n",
    "2.  **Interaction Features**: Yes, applied in Step 3 above.\n",
    "3.  **Target Transformation (Yeo-Johnson)**: **Yes**, but this is applied **during training** (inside the `run.py` module). \n",
    "    *   Since the transformation acts on the target `y`, it's best integrated into the `train_model` function so it can be properly inverse-transformed for predictions and error calculation on the fly.\n",
    "    *   It is currently active for **every** model trained in the loop below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e317582a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized HPO loop with max_iters=100, max_combos=3\n"
     ]
    }
   ],
   "source": [
    "from training.config_utils import crossover_config, generate_random_config\n",
    "\n",
    "# Setup Loop Variables\n",
    "max_iters = config[\"training\"][\"max_iters\"]\n",
    "max_combos = config[\"training\"][\"max_combos\"]\n",
    "\n",
    "# Initialize current_cfg\n",
    "current_cfg = generate_random_config()\n",
    "print(f\"Initialized HPO loop with max_iters={max_iters}, max_combos={max_combos}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ab3a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training.run reloaded with TransformedTargetRegressor fix.\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import training.run\n",
    "importlib.reload(training.run)\n",
    "from training.run import optimize_hyperparameters\n",
    "print(\"training.run reloaded with TransformedTargetRegressor fix.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021ecdd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iter 33/100 — Strategy: TOP\n",
      "Optimizing hyperparameters over grid: {'learning_rate': [0.3221966168924104, 0.007819515626402838, 0.006397785512511412], 'n_estimators': [1980, 1800, 1620], 'num_leaves': [569, 518, 466], 'max_depth': [100, 94, 84], 'min_child_samples': [158, 144, 129], 'reg_alpha': [9.695187078391255, 0.5102285769113253, 0.41745974474562975], 'reg_lambda': [2.837802523458497, 2.5798204758713608, 2.3218384282842246], 'subsample': [0.9233412332969095, 0.7554610090611077, 0.41281112572356593], 'colsample_bytree': [0.3228352225904187, 0.2934865659912897, 0.26413790939216075], 'min_split_gain': [0.40859769615825575, 0.37145245105295976, 0.3343072059476638], 'early_stopping_rounds': [191, 48, 39]}\n",
      "Evaluating hyperparameter combo 1/3, with params: {'learning_rate': 0.007819515626402838, 'n_estimators': 1620, 'num_leaves': 518, 'max_depth': 94, 'min_child_samples': 129, 'reg_alpha': 0.5102285769113253, 'reg_lambda': 2.837802523458497, 'subsample': 0.41281112572356593, 'colsample_bytree': 0.2934865659912897, 'min_split_gain': 0.3343072059476638, 'early_stopping_rounds': 48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training LightGBM: 100%|██████████| 1620/1620 [00:29<00:00, 55.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2=0.4193, time=29.2571s for Evaluated params {'learning_rate': 0.007819515626402838, 'n_estimators': 1620, 'num_leaves': 518, 'max_depth': 94, 'min_child_samples': 129, 'reg_alpha': 0.5102285769113253, 'reg_lambda': 2.837802523458497, 'subsample': 0.41281112572356593, 'colsample_bytree': 0.2934865659912897, 'min_split_gain': 0.3343072059476638, 'early_stopping_rounds': 48}\n",
      "Evaluating hyperparameter combo 2/3, with params: {'learning_rate': 0.007819515626402838, 'n_estimators': 1620, 'num_leaves': 569, 'max_depth': 84, 'min_child_samples': 144, 'reg_alpha': 0.5102285769113253, 'reg_lambda': 2.3218384282842246, 'subsample': 0.9233412332969095, 'colsample_bytree': 0.3228352225904187, 'min_split_gain': 0.3343072059476638, 'early_stopping_rounds': 191}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training LightGBM: 100%|██████████| 1620/1620 [00:27<00:00, 58.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2=0.4202, time=27.7584s for Evaluated params {'learning_rate': 0.007819515626402838, 'n_estimators': 1620, 'num_leaves': 569, 'max_depth': 84, 'min_child_samples': 144, 'reg_alpha': 0.5102285769113253, 'reg_lambda': 2.3218384282842246, 'subsample': 0.9233412332969095, 'colsample_bytree': 0.3228352225904187, 'min_split_gain': 0.3343072059476638, 'early_stopping_rounds': 191}\n",
      "Evaluating hyperparameter combo 3/3, with params: {'learning_rate': 0.007819515626402838, 'n_estimators': 1800, 'num_leaves': 569, 'max_depth': 100, 'min_child_samples': 144, 'reg_alpha': 0.41745974474562975, 'reg_lambda': 2.5798204758713608, 'subsample': 0.9233412332969095, 'colsample_bytree': 0.2934865659912897, 'min_split_gain': 0.37145245105295976, 'early_stopping_rounds': 191}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training LightGBM:  26%|██▋       | 476/1800 [00:09<00:23, 56.05it/s]"
     ]
    }
   ],
   "source": [
    "# Optimization Loop\n",
    "for i in range(max_iters):\n",
    "    clear_output(wait=True)\n",
    "    # Refresh references\n",
    "    top_cfg = config[\"training\"][\"top\"]\n",
    "    fastest_cfg = config[\"training\"][\"fastest\"]\n",
    "    slowest_cfg = config[\"training\"][\"slowest\"]\n",
    "    \n",
    "    max_combos = config[\"training\"][\"max_combos\"]\n",
    "\n",
    "    # Strategy selection\n",
    "    rand_val = random.random()\n",
    "    if rand_val < 0.05:\n",
    "        base_cfg = current_cfg\n",
    "        strategy = \"RANDOM_START\"\n",
    "    elif rand_val < 0.25:\n",
    "        base_cfg = fastest_cfg\n",
    "        strategy = \"FASTEST\"\n",
    "    elif rand_val < 0.60:\n",
    "        base_cfg = top_cfg\n",
    "        strategy = \"TOP\"\n",
    "    elif rand_val < 0.85:\n",
    "        # Crossover\n",
    "        candidates = [\n",
    "            c for c in [top_cfg, fastest_cfg, slowest_cfg] if c[\"best_score\"] > -9999\n",
    "        ]\n",
    "        if len(candidates) < 2:\n",
    "            candidates = [c for c in [top_cfg, fastest_cfg, current_cfg] if c]\n",
    "            if len(candidates) < 2:\n",
    "                candidates = [generate_random_config(), generate_random_config()]\n",
    "\n",
    "        parents = random.sample(candidates, 2)\n",
    "        base_cfg = crossover_config(dict(parents[0]), dict(parents[1]))\n",
    "        strategy = \"CROSSOVER\"\n",
    "    else:\n",
    "        base_cfg = slowest_cfg\n",
    "        strategy = \"SLOWEST\"\n",
    "        # max_combos = 1\n",
    "\n",
    "    print(f\"\\nIter {i + 1}/{max_iters} — Strategy: {strategy}\")\n",
    "\n",
    "    # optimize_hyperparameters handles updates and saving internally now.\n",
    "    results = optimize_hyperparameters(\n",
    "        base_cfg=base_cfg, max_combos=max_combos, X=X, y=y, strategy=strategy\n",
    "    )\n",
    "\n",
    "    # Info only loop\n",
    "    for candidate_cfg, metrics in results:\n",
    "        r2 = metrics[\"r2\"]\n",
    "        t_time = metrics[\"training_time\"]\n",
    "\n",
    "        # Check if this result matches current bests (just for log/info)\n",
    "        is_top = r2 == top_cfg[\"best_score\"]\n",
    "        is_fastest = t_time == fastest_cfg[\"training_time\"]\n",
    "\n",
    "        if is_top:\n",
    "            print(f\"  [Info] This batch produced the current TOP score: {r2:.6f}\")\n",
    "        if is_fastest:\n",
    "            print(\n",
    "                f\"  [Info] This batch produced the current FASTEST time: {t_time:.4f}s\"\n",
    "            )\n",
    "\n",
    "    # Refresh local current_cfg for next RANDOM_START or Crossover inheritance\n",
    "    if results:\n",
    "        # Simply take the last one as 'current' for random drift\n",
    "        current_cfg = results[-1][0]\n",
    "\n",
    "print(f\"\\nFinished optimization.\")\n",
    "print(f\"Top R2: {top_cfg['best_score']:.6f}\")\n",
    "print(\n",
    "    f\"Fastest Time: {fastest_cfg['training_time']:.6f}s (R2: {fastest_cfg['best_score']:.6f})\"\n",
    ")\n",
    "print(\n",
    "    f\"Slowest (High Score) Time: {slowest_cfg['training_time']:.6f}s (R2: {slowest_cfg['best_score']:.6f})\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
